{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import optim\n",
    "from hydra.experimental import compose, initialize\n",
    "from omegaconf import DictConfig\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RNNSM.rnnsm import RNNSM\n",
    "from RMTPP.rmtpp import RMTPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATMDataset(Dataset):\n",
    "    def __init__(self, path, max_len=500, normalization='none'):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        data = pd.read_csv(path)\n",
    "        self.ids = data['id']\n",
    "        self.times = data['time']\n",
    "        self.events = data['event'] + 1\n",
    "        self.time_seqs, self.event_seqs = self.generate_sequence()\n",
    "        \n",
    "            \n",
    "\n",
    "    def generate_sequence(self):\n",
    "        time_seqs = []\n",
    "        event_seqs = []\n",
    "        cur_start, cur_end = 0, 1\n",
    "        \n",
    "        # нарезка датасета по последовательностям с одним id и максимальной длиной self.max_len\n",
    "        while cur_start < len(self.ids):\n",
    "            if cur_end < len(self.ids) and \\\n",
    "                    self.ids[cur_start] == self.ids[cur_end] and \\\n",
    "                    cur_end - cur_start < self.max_len:\n",
    "                cur_end += 1\n",
    "                continue\n",
    "            else:\n",
    "                time_seqs.append(torch.Tensor(self.times[cur_start:cur_end].to_numpy()))\n",
    "                event_seqs.append(torch.LongTensor(self.events[cur_start:cur_end].to_numpy()))\n",
    "                cur_start, cur_end = cur_end, cur_end + 1\n",
    "\n",
    "        return time_seqs, event_seqs\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.time_seqs[item], self.event_seqs[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_seqs)\n",
    "\n",
    "    \n",
    "def pad_collate(batch):\n",
    "  (xx, yy) = zip(*batch)\n",
    "  x_lens = [len(x) for x in xx]\n",
    "  y_lens = [len(y) for y in yy]\n",
    "  xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "  yy_pad = pad_sequence(yy, batch_first=True, padding_value=0)\n",
    "\n",
    "  return xx_pad[..., None], yy_pad[..., None], x_lens, y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ATMDataset('data/ATM/train_day.csv')\n",
    "data_loader = DataLoader(dataset=ds, batch_size=32, shuffle=True, collate_fn=pad_collate, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.experimental.initialize()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize(config_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rmtpp(data_loader, model, cfg: DictConfig):\n",
    "    train_metrics = defaultdict(list)\n",
    "\n",
    "    for epoch in range(cfg.training.n_epochs):\n",
    "        print(f'Epoch {epoch+1}/{cfg.training.n_epochs}....')\n",
    "        losses = []\n",
    "        for times, events, lengths, _ in data_loader:\n",
    "            time_deltas = torch.cat([torch.zeros(times.shape[0], 1, times.shape[2]),\n",
    "                                     times[:, 1:] - times[:, :-1]],\n",
    "                                     dim=1)\n",
    "            o_t, y_t = model(events, time_deltas, lengths)\n",
    "            padding_mask = torch.isclose(times, torch.Tensor([0]))\n",
    "            ret_mask = ~padding_mask\n",
    "            loss = model.compute_loss(time_deltas, padding_mask, o_t, y_t[0], events)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "        train_metrics['loss'].append(np.mean(losses))\n",
    "        print(train_metrics['loss'][-1])\n",
    "    return train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10....\n",
      "-2.1617333507363465\n",
      "Epoch 2/10....\n",
      "-3.1642438644107354\n",
      "Epoch 3/10....\n",
      "-3.6396667602214405\n",
      "Epoch 4/10....\n",
      "-3.7764306677148696\n",
      "Epoch 5/10....\n",
      "-3.0389498878032604\n",
      "Epoch 6/10....\n",
      "-3.2186425619937005\n",
      "Epoch 7/10....\n",
      "-2.912486532901196\n",
      "Epoch 8/10....\n",
      "-3.494121346067875\n",
      "Epoch 9/10....\n",
      "-3.2129714057800616\n",
      "Epoch 10/10....\n",
      "-3.8959539481934082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'loss': [-2.1617333507363465,\n",
       "              -3.1642438644107354,\n",
       "              -3.6396667602214405,\n",
       "              -3.7764306677148696,\n",
       "              -3.0389498878032604,\n",
       "              -3.2186425619937005,\n",
       "              -2.912486532901196,\n",
       "              -3.494121346067875,\n",
       "              -3.2129714057800616,\n",
       "              -3.8959539481934082]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RMTPP(cfg.rmtpp)\n",
    "opt = optim.Adam(model.parameters(), lr=cfg.training.lr)\n",
    "train_rmtpp(data_loader, model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnnsm(data_loader, model, cfg: DictConfig):\n",
    "    train_metrics = defaultdict(list)\n",
    "\n",
    "    for epoch in range(cfg.training.n_epochs):\n",
    "        print(f'Epoch {epoch+1}/{cfg.training.n_epochs}....')\n",
    "        losses = []\n",
    "        for times, events, lengths, _ in data_loader:\n",
    "            time_deltas = torch.cat([torch.zeros(times.shape[0], 1, times.shape[2]),\n",
    "                                     times[:, 1:] - times[:, :-1]],\n",
    "                                     dim=1)\n",
    "            o_t = model(events, time_deltas, lengths)\n",
    "            padding_mask = torch.isclose(times, torch.Tensor([0]))\n",
    "            ret_mask = ~padding_mask\n",
    "            loss = model.compute_loss(time_deltas, padding_mask, ret_mask, o_t)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "        train_metrics['loss'].append(np.mean(losses))\n",
    "        print(train_metrics['loss'][-1])\n",
    "    return train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10....\n",
      "-3.1207775065397962\n",
      "Epoch 2/10....\n",
      "-6.634248429156364\n",
      "Epoch 3/10....\n",
      "-7.0342806045045245\n",
      "Epoch 4/10....\n",
      "-7.286588881878143\n",
      "Epoch 5/10....\n",
      "-7.377609050020259\n",
      "Epoch 6/10....\n",
      "-7.448889072905195\n",
      "Epoch 7/10....\n",
      "-7.542163503930924\n",
      "Epoch 8/10....\n",
      "-7.602628535412728\n",
      "Epoch 9/10....\n",
      "-7.629863891195743\n",
      "Epoch 10/10....\n",
      "-7.657119903158634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'loss': [-3.1207775065397962,\n",
       "              -6.634248429156364,\n",
       "              -7.0342806045045245,\n",
       "              -7.286588881878143,\n",
       "              -7.377609050020259,\n",
       "              -7.448889072905195,\n",
       "              -7.542163503930924,\n",
       "              -7.602628535412728,\n",
       "              -7.629863891195743,\n",
       "              -7.657119903158634]})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNSM(cfg.rnnsm)\n",
    "opt = optim.Adam(model.parameters(), lr=cfg.training.lr)\n",
    "train_rnnsm(data_loader, model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
